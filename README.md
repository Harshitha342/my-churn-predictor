# Customer Churn Prediction â€“ End-to-End ML Pipeline

## ğŸ“Œ Overview
This project implements an end-to-end **machine learning pipeline** to predict **customer churn** for a telecommunications company.  
It covers **data preprocessing**, **model training and evaluation**, **REST API deployment**, **containerization with Docker**, and **automated testing**.

The goal is to demonstrate practical skills in **applied machine learning** and **MLOps** using Python.

---

## ğŸ§  Problem Statement
Customer churn occurs when customers stop using a companyâ€™s services. Predicting churn enables businesses to proactively retain customers through targeted actions.

This system predicts whether a customer will churn (`Yes` / `No`) along with the **probability of churn**.

---

## ğŸ—‚ Dataset
- **Name:** Telco Customer Churn Dataset (IBM)
- **Source:** Kaggle (official mirror)
- **Rows:** 7,043  
- **Features:** 20  
- **Target:** `Churn` (Yes / No)

> Dataset was sourced from Kaggle due to deprecated public links, while maintaining identical structure and columns.

---

## âš™ï¸ Tech Stack
- **Python 3**
- **pandas, numpy**
- **scikit-learn**
- **Flask**
- **joblib**
- **pytest**
- **Docker**

---

## ğŸ— Project Structure

my-churn-predictor/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ main.py # Flask API
â”‚ â”œâ”€â”€ model.py # Model training & preprocessing
â”‚ â””â”€â”€ utils.py
â”œâ”€â”€ data/
â”‚ â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â”œâ”€â”€ models/
â”‚ â””â”€â”€ churn_model.joblib
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_api.py
â”‚ â”œâ”€â”€ test_model.py
â”‚ â””â”€â”€ conftest.py
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .env.example

---

## ğŸ”¬ Model Details
- **Algorithm:** Logistic Regression
- **Preprocessing:**
  - OneHotEncoding for categorical features
  - StandardScaler for numerical features
  - Handling missing values
- **Train/Test Split:** 80/20 (stratified)

### ğŸ“Š Evaluation Metrics (on Test Set)
- **Accuracy:** ~80%
- **Precision:** ~65%
- **Recall:** ~55%
- **F1-score:** ~60%

> Precision, Recall, and F1-score are emphasized due to class imbalance in churn prediction.

---

## ğŸš€ Running the Application (Local)

### 1ï¸âƒ£ Setup Virtual Environment

python -m venv .venv
source .venv/Scripts/activate   # Git Bash
### 2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

###  3ï¸âƒ£ Train the Model
python app/model.py

### 4ï¸âƒ£ Start the API
python app/main.py


API runs at:
http://127.0.0.1:8000

Available endpoint:
POST /predict


ğŸ”Œ API Usage
Endpoint
POST /predict

Request Body (JSON)
{
  "gender": "Female",
  "SeniorCitizen": 0,
  "Partner": "Yes",
  "Dependents": "No",
  "tenure": 12,
  "PhoneService": "Yes",
  "MultipleLines": "No",
  "InternetService": "Fiber optic",
  "OnlineSecurity": "No",
  "OnlineBackup": "Yes",
  "DeviceProtection": "No",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "No",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 75.5,
  "TotalCharges": 900.0
}

Response
{
  "prediction": "Yes",
  "probability": 0.67
}

Error Handling

400 Bad Request â†’ missing/invalid input

500 Internal Server Error â†’ server issues

ğŸ§ª Running Tests
pytest


âœ” Includes:

model existence & prediction tests

API success and validation tests

ğŸ³ Running with Docker
Build Image
docker build -t churn-predictor .

Run Container
docker run -p 8000:8000 churn-predictor


API will be accessible at:

http://127.0.0.1:8000

ğŸ§© Design Decisions

Logistic Regression chosen for interpretability and fast inference

scikit-learn Pipeline used to prevent data leakage

Single saved pipeline ensures preprocessing consistency

Dockerized deployment ensures reproducibility

ğŸ“Œ Conclusion

This project demonstrates a production-ready ML workflow from raw data to deployment.
It reflects real-world practices in ML engineering and MLOps, including testing, API development, and containerization.

ğŸ‘©â€ğŸ’» Author

Harshitha Arlapalli